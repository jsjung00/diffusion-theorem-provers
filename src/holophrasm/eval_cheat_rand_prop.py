from data_utils import *
import data_loader_pred
import params
import numpy as np

args = params.get_args()
loader = MetaMath(args, split='valid', evaluate=True)

threshold = np.array(range(100), dtype=np.float64)/100*4+1

ranks = {}
for t in threshold:
    ranks[t] = []

def get_rank(l, t, k=100):
    a = 0
    for i in range(k):
        scores = np.random.normal(size=l)
        r = (scores>t).sum()
        a += 1.0/(1+r)
    return a/k
for idx in range(len(loader.steps)):
    labels = [loader.lm.database.propositions[p].number for p in loader.props[idx] if p != 'quartfull' and len(loader.lm.database.propositions[p].e) > 0]
    scores = np.random.normal(size=len(labels))
    for t in threshold:
        ranks[t].append(get_rank(len(labels), t, k=10))
    if idx % 100 == 99:
        print(idx)

'''
1.0 0.032751697404126985
1.04 0.034840403238732616
1.08 0.03710663079135052
1.12 0.03957062543914268
1.16 0.04219538595329224
1.2 0.04513236798822112
1.24 0.048286417255337
1.28 0.051778075221289195
1.32 0.05553036346050196
1.3599999999999999 0.05963217608981307
1.4 0.06420579460526649
1.44 0.06922216947621426
1.48 0.0745380419501572
1.52 0.08044327922435143
1.56 0.08698672001764643
1.6 0.09409031118039252
1.6400000000000001 0.10169480006318939
1.6800000000000002 0.10997779104340837
1.72 0.11914528829136979
1.76 0.12901117904401788
1.8 0.13988266181767223
1.8399999999999999 0.1519190346984808
1.88 0.16432621639667727
1.92 0.17838081656168733
1.96 0.1932265199006264
2.0 0.20937097690074535
2.04 0.22667049503714193
2.08 0.24521561393022767
2.12 0.26576384687303467
2.16 0.2870659481470067
2.2 0.309775799147169
2.24 0.33466643929847867
2.2800000000000002 0.3597237487025384
2.3200000000000003 0.386494628387499
2.3600000000000003 0.4152114846226678
2.4 0.4439992010961025
2.44 0.4739396729520034
2.48 0.5042504326439965
2.52 0.5348128982263886
2.56 0.5653621518740909
2.6 0.596072320668737
2.6399999999999997 0.6259296369605747
2.6799999999999997 0.655038078539652
2.7199999999999998 0.6839244142076616
2.76 0.710801858057841
2.8 0.7375071668108146
2.84 0.7622632466231604
2.88 0.7848535236914198
2.92 0.8069813813905351
2.96 0.8269085507897379
3.0 0.8454572579710588
3.04 0.8622938131338136
3.08 0.8778290778619126
3.12 0.8920979013832955
3.16 0.9048426310016159
3.2 0.916331140037009
3.24 0.9264195632477865
3.28 0.9356054212556726
3.32 0.9438126639009509
3.36 0.9509410909261505
3.4 0.9573966766792448
3.44 0.9630295618172751
3.48 0.9681340771465105
3.52 0.9725686358648625
3.56 0.9761754398509509
3.6 0.9794850998900592
3.64 0.982361607781179
3.68 0.9850652028796602
3.72 0.9871446621844963
3.76 0.989058193868112
3.8 0.9906095932864339
3.84 0.992114027559092
3.88 0.9933413197919798
3.92 0.994356553664116
3.96 0.9950709245218972
4.0 0.9959371572973916
4.04 0.9964974014207976
4.08 0.9971210604109406
4.12 0.9974688885709606
4.16 0.9980083917417176
4.2 0.9982272445524785
4.24 0.9985378820387757
4.279999999999999 0.9987858198636043
4.32 0.9989937061936534
4.359999999999999 0.9991658322605057
4.4 0.9992926619939748
4.4399999999999995 0.9994061412291845
4.48 0.9994964954941944
4.52 0.9996059218995762
4.5600000000000005 0.9996838792733447
4.6 0.9997017594049414
4.640000000000001 0.9997689886997513
4.68 0.999805464168212
4.720000000000001 0.9998505220998389
4.76 0.9998734086682846
4.8 0.9998920040051468
4.84 0.9999127449578009
4.88 0.9999320554999266
4.92 0.9999392075525664
4.96 0.9999549420683724
'''